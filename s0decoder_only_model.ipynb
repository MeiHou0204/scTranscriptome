{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2c48db",
   "metadata": {},
   "source": [
    "# we create a decoder-only model to see how it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5666c68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 示例数据：2个细胞 × 3个基因（模拟log-normalized表达量）\n",
    "data = torch.tensor([\n",
    "    [0.1, 0.5, 1.2],  # 细胞1\n",
    "    [0.3, 0.8, 0.4]   # 细胞2\n",
    "], dtype=torch.float32)  # shape: (batch_size=2, num_genes=3)\n",
    "\n",
    "# 超小Decoder-only模型\n",
    "class TinyDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(3, 4)  # 基因维度3 → 隐藏层4\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=4, nhead=2, batch_first=True\n",
    "        )\n",
    "        self.output = nn.Linear(4, 3)  # 输出维度=基因数\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_embed = self.embed(x)  # (batch_size, num_genes, hidden_dim)\n",
    "        # 自回归掩码：下三角矩阵（防止信息泄露）\n",
    "        mask = torch.triu(torch.ones(3, 3), diagonal=1).bool()  # shape: (seq_len, seq_len)\n",
    "        output = self.decoder_layer(\n",
    "            tgt=x_embed,         # 输入嵌入\n",
    "            memory=None,        # 无Encoder输入\n",
    "            tgt_mask=mask        # 因果掩码\n",
    "        )\n",
    "        return self.output(output)\n",
    "\n",
    "model = TinyDecoder()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
