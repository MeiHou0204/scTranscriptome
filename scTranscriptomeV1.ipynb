{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690baa46",
   "metadata": {},
   "source": [
    "## A scripts to simulate and clustering single cell transcriptome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a89f0f",
   "metadata": {},
   "source": [
    "## step1. simulating single cell transcriptome data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe21ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import lognorm, poisson\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_realistic_scRNAseq_data(n_cells=40000, n_genes=2000, n_clusters=5,n_housekeeping=20):\n",
    "    # 参数设置\n",
    "    cells_per_cluster = n_cells // n_clusters\n",
    "    \n",
    "    # 1. 创建基础表达矩阵（21000×2000，初始为0）\n",
    "    data = np.zeros((n_cells, n_genes))\n",
    "    labels = np.array([])\n",
    "    # 2. 定义基因分组\n",
    "    # np.random.seed(4211)\n",
    "    # 20个所有群体共表达的基因\n",
    "    common_genes = np.random.choice(n_genes, n_housekeeping, replace=False)\n",
    "    \n",
    "    # 每群特异表达的基因~50 genes\n",
    "    cluster_specific = { 'cell%s'%(i): np.random.choice(list(set(range(n_genes)) - set(common_genes)), 50) for i in range(n_clusters)}\n",
    "    # 3. 生成每群细胞的表达模式\n",
    "    for i, cluster in enumerate(['cell%s'%(i) for i in range(n_clusters)]):\n",
    "        start = i * cells_per_cluster\n",
    "        end = (i+1) * cells_per_cluster\n",
    "        labels = np.append(labels, [cluster] * cells_per_cluster)\n",
    "        # 所有细胞都表达common genes\n",
    "        data[start:end, common_genes] = lognorm.rvs(s=1, scale=10, size=(cells_per_cluster, n_housekeeping))\n",
    "        \n",
    "        # 群体特异基因\n",
    "        spec_genes = cluster_specific[cluster]\n",
    "        n_spec = len(spec_genes)\n",
    "        for cell_idx in range(start, end):\n",
    "            # 每个细胞随机表达50-200个基因\n",
    "            expressed = np.random.choice(spec_genes, np.random.randint(15, n_spec), replace=False)\n",
    "            \n",
    "            # 表达值分布：大部分低表达，少数高表达\n",
    "            low_expr = lognorm.rvs(s=1, scale=5, size=len(expressed)//2)\n",
    "            high_expr = lognorm.rvs(s=1, scale=1e3, size=len(expressed)-len(low_expr))\n",
    "            data[cell_idx, expressed] = np.concatenate([low_expr, high_expr])\n",
    "            \n",
    "            # 添加dropout效果（60%个基因为 gene do not express）\n",
    "            zeros = np.random.choice(n_genes, int(n_genes*0.6), replace=False)\n",
    "            data[cell_idx, zeros] = 0\n",
    "    \n",
    "    # 4. 添加技术噪声和归一化\n",
    "    data = data * poisson.rvs(1, size=data.shape)  # 泊松噪声\n",
    "    data = data / data.sum(axis=1, keepdims=True) * 1e6  # TPM归一化\n",
    "    # 5. 创建DataFrame\n",
    "    df = pd.DataFrame(data, columns=[f'Gene_{i}' for i in range(n_genes)])\n",
    "    df['Cell_Label'] = labels\n",
    "    \n",
    "    return df\n",
    "\n",
    "##visualization\n",
    "def visualize_with_umap(X,Ylabel,savepath='/XYFS01/HDD_POOL/sysu_mhou/sysu_mhou_1/deep_learning_book/practices/decoder_only_SingleCellTranscriptome/example/figs',figname='Simu_cell_type_umap.png'):\n",
    "    # UMAP降维\n",
    "    reducer = UMAP(n_components=2,n_jobs=4)# random seed would not allow parallelization\n",
    "    embedding = reducer.fit_transform(np.log1p(X))  # log1p转换使分布更接近正态\n",
    "    \n",
    "    # 可视化\n",
    "    unique_labels = np.unique(Ylabel)\n",
    "    palette_lst = sns.color_palette(\"tab20\", n_colors=len(unique_labels))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x=embedding[:, 0], y=embedding[:, 1],\n",
    "        hue=Ylabel, palette=palette_lst,hue_order=unique_labels,\n",
    "        alpha=0.6, s=10\n",
    "    )\n",
    "    plt.title('UMAP Visualization of Synthetic scRNA-seq Data',fontsize=20)\n",
    "    plt.xlabel('UMAP1', fontsize=18)\n",
    "    plt.ylabel('UMAP2', fontsize=18)\n",
    "    plt.legend(title='Cell Type',title_fontsize=16, fontsize=16, loc='lower right')\n",
    "    # plt.savefig(f\"{savepath}/{figname}\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 生成数据\n",
    "    sc_data = generate_realistic_scRNAseq_data(n_clusters=5,n_housekeeping=40)\n",
    "    sc_data.to_csv('/XYFS01/HDD_POOL/sysu_mhou/sysu_mhou_1/deep_learning_book/practices/decoder_only_SingleCellTranscriptome/example/scRNAseq_SimuData.csv', index=False)\n",
    "    visualize_with_umap(X=sc_data.drop(columns=['Cell_Label']).values,Ylabel=sc_data['Cell_Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9978355",
   "metadata": {},
   "source": [
    "## step2. training a transformer (decoder-only) model to learn cell representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SingleCellDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 20000,  # 单细胞数据的基因数（输入维度）\n",
    "        hidden_dim: int = 512,   # 隐藏层维度\n",
    "        num_layers: int = 2,     # Transformer层数\n",
    "        nhead: int = 4,          # 多头注意力头数\n",
    "        dropout: float = 0.1,    # Dropout率\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 输入嵌入层（基因表达 → 隐藏层）\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=nhead,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,#batch_first=True 的功能是让输入张量的形状以 (batch_size, 序列长度, 特征维度) 排列，而不是默认的 (序列长度, batch_size, 特征维度)\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        \n",
    "        # 输出层（隐藏层 → 基因表达重建）\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        输入: \n",
    "            x: (batch_size, seq_len, input_dim)  # 单细胞基因表达矩阵\n",
    "        输出: \n",
    "            (batch_size, seq_len, input_dim)     # 重建的基因表达\n",
    "        \"\"\"\n",
    "        # 1. 嵌入层\n",
    "        x_embed = self.embedding(x)  # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # 2. 自注意力解码（无交叉注意力）\n",
    "        memory = torch.zeros_like(x_embed)  # 无encoder输入，仅自回归\n",
    "        output = self.transformer_decoder(\n",
    "            tgt=x_embed,## 目标序列（当前要生成的序列）\n",
    "            memory=memory,## 无Encoder，用全零占位\n",
    "        )\n",
    "        \n",
    "        # 3. 输出重建\n",
    "        return self.output_layer(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19857a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1. 准备数据（假设sc_data是DataFrame，形状为(21000, genes+1)，最后一列是cell_type）\n",
    "X = sc_data.iloc[:, :-1].values  # 基因表达数据 (21000, n_genes)\n",
    "y = sc_data.iloc[:, -1].values    # 细胞类型标签\n",
    "n_genes = X.shape[1]\n",
    "\n",
    "# 转换为PyTorch张量并添加序列维度 (21000, 1, n_genes)\n",
    "X_tensor = torch.FloatTensor(X).unsqueeze(1)\n",
    "\n",
    "# 2. 划分训练集和测试集 (8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. 创建数据加载器\n",
    "batch_size = 100\n",
    "train_dataset = TensorDataset(X_train, torch.LongTensor(y_train))\n",
    "test_dataset = TensorDataset(X_test, torch.LongTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 4. 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SingleCellDecoder(input_dim=n_genes).to(device)\n",
    "\n",
    "# 5. 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 假设是基因表达重建任务\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 6. 训练循环\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # 批量训练\n",
    "    for batch_X, _ in train_loader:  # 忽略标签（无监督学习）\n",
    "        batch_X = batch_X.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        reconstructed = model(batch_X)\n",
    "        loss = criterion(reconstructed, batch_X)  # 自编码器重建损失\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    # 计算epoch平均损失\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 测试集验证\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            reconstructed = model(batch_X)\n",
    "            test_loss += criterion(reconstructed, batch_X).item() * batch_X.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# 7. 保存模型\n",
    "torch.save(model.state_dict(), 'sc_decoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f6bfc",
   "metadata": {},
   "source": [
    "## step 3. model evalutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
